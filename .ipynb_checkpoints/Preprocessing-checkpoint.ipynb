{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import needed libarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./Dataset/train.csv\")\n",
    "train.drop(['discourse_id', 'essay_id'] , axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########## Clean data\n",
    "def cleanText(df):\n",
    "\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    lengthArr = []\n",
    "    wordCountArr = []\n",
    "    sentCountArr = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        curText = row.discohttps://app.joinhandshake.com/stu/jobs/6688609?ref=preview-header-clickrse_text\n",
    "\n",
    "        # lower case conversion\n",
    "        curText = curText.lower()\n",
    "        # removes all the trailing and leading spaces\n",
    "        curText = curText.strip()\n",
    "\n",
    "        # Saves the lengths of the writing from the model\n",
    "        lengthArr.append(len(curText))\n",
    "        wordCountArr.append(len(curText.split()))\n",
    "        #\n",
    "        sentCountArr.append(len([x for x in re.split(r\"[\\n\\.\\?\\!]+\", curText) if len(x) > 0]))\n",
    "\n",
    "        #Removes stop words\n",
    "        def remove_stop(x):\n",
    "            return \" \".join([word for word in str(x).split() if word not in stopWords])\n",
    "\n",
    "        curText = remove_stop(curText)\n",
    "\n",
    "        # removing all non alpha numeric char\n",
    "        curText = re.sub(r'[^a-z0-9 ]+', '', curText)\n",
    "        # removing \"...\" (multiple periods in a row)\n",
    "        curText = re.sub(r'([.])\\1+', '', curText)\n",
    "        # stems the text\n",
    "        curText = stemmer.stem(curText)\n",
    "\n",
    "        # removing multiple spaces in a row\n",
    "        curText = re.sub(r'(\\s\\s)+', ' ', curText)\n",
    "\n",
    "        # replaces the text\n",
    "        df.at[index, 'discourse_text'] = curText\n",
    "\n",
    "    df['StringLength'] = lengthArr\n",
    "    df['WordCount'] = wordCountArr\n",
    "    df['SentenceCount'] = sentCountArr\n",
    "\n",
    "\n",
    "cleanText(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized strings\n",
    "countVec = CountVectorizer(\n",
    "    ngram_range=(1,2),\n",
    "    min_df=15\n",
    ")\n",
    "\n",
    "# Fits the vectorized with train data\n",
    "train_vectors = countVec.fit_transform(train['discourse_text'])\n",
    "\n",
    "# Gets a list of all the words in the vector\n",
    "vector_features = countVec.get_feature_names()\n",
    "# print(\"Vector features: \", vector_features)  # Prints all the words fit intoz the in the vectorizer\n",
    "print(\"Feature Counts: \", len(vector_features), \"\\n\\n\")  # Prints the amount of words in the vectorizer\n",
    "# Converts the vectorized data matrix to array\n",
    "train_vec_arr = train_vectors.toarray()\n",
    "# Puts the vectorized data into the dataframe\n",
    "train_vec_dataframe = pd.DataFrame(data=train_vec_arr, columns=vector_features)\n",
    "\n",
    "# One hot encodes discourse type\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "X_categorical_OneHot_train = pd.DataFrame(OH_encoder.fit_transform(train[['discourse_type']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineDataFrame(dfOg, restDfs):\n",
    "    df = dfOg.copy()\n",
    "\n",
    "    # drops the text column as it has been vectorized and type since it's been one hot encoded\n",
    "    df.drop(['discourse_text', 'discourse_type'], inplace=True, axis=1)\n",
    "\n",
    "    if 'discourse_effectiveness'in df:\n",
    "        # ordinally encodes effectivness\n",
    "        df['discourse_effectiveness'] = dfOg[\"discourse_effectiveness\"].replace(\n",
    "            {\"Ineffective\": 0, \"Adequate\": 1, \"Effective\": 2}\n",
    "        )\n",
    "\n",
    "    for curDf in restDfs:\n",
    "        df = pd.concat([df, curDf], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Gets the combined and fully cleaned model\n",
    "trainFullyCombined = combineDataFrame(train, [X_categorical_OneHot_train, train_vec_dataframe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs oversampling\n",
    "ros = RandomOverSampler(sampling_strategy='auto', random_state=0)\n",
    "\n",
    "processedY = trainFullyCombined['discourse_effectiveness']\n",
    "trainFullyCombined.drop(['discourse_effectiveness'], axis=1, inplace=True)\n",
    "\n",
    "xResampled, yResampled = ros.fit_resample(trainFullyCombined, processedY)\n",
    "\n",
    "trainFullyProcessed = xResampled\n",
    "trainFullyProcessed['discourse_effectiveness'] = yResampled\n",
    "\n",
    "print(\"Categories After: \", train['discourse_effectiveness'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainFullyProcessed.head())\n",
    "trainFullyProcessed.to_csv('./Dataset/trainFullyProcessed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
