{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009407,
     "end_time": "2022-08-08T09:32:23.300039",
     "exception": false,
     "start_time": "2022-08-08T09:32:23.290632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Import needed libarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T08:45:57.538248Z",
     "iopub.status.busy": "2022-08-10T08:45:57.537796Z",
     "iopub.status.idle": "2022-08-10T08:45:57.546043Z",
     "shell.execute_reply": "2022-08-10T08:45:57.544908Z",
     "shell.execute_reply.started": "2022-08-10T08:45:57.538217Z"
    },
    "papermill": {
     "duration": 2.167838,
     "end_time": "2022-08-08T09:32:25.475481",
     "exception": false,
     "start_time": "2022-08-08T09:32:23.307643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007134,
     "end_time": "2022-08-08T09:32:25.490230",
     "exception": false,
     "start_time": "2022-08-08T09:32:25.483096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T08:45:57.567059Z",
     "iopub.status.busy": "2022-08-10T08:45:57.565944Z",
     "iopub.status.idle": "2022-08-10T08:45:57.742246Z",
     "shell.execute_reply": "2022-08-10T08:45:57.741020Z",
     "shell.execute_reply.started": "2022-08-10T08:45:57.567018Z"
    },
    "papermill": {
     "duration": 0.326065,
     "end_time": "2022-08-08T09:32:25.823994",
     "exception": false,
     "start_time": "2022-08-08T09:32:25.497929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./Dataset/train.csv\")\n",
    "\n",
    "submission = pd.read_csv(\"./Dataset/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007207,
     "end_time": "2022-08-08T09:32:25.838881",
     "exception": false,
     "start_time": "2022-08-08T09:32:25.831674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Analyze Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T08:45:57.744550Z",
     "iopub.status.busy": "2022-08-10T08:45:57.744211Z",
     "iopub.status.idle": "2022-08-10T08:45:57.775957Z",
     "shell.execute_reply": "2022-08-10T08:45:57.774363Z",
     "shell.execute_reply.started": "2022-08-10T08:45:57.744519Z"
    },
    "papermill": {
     "duration": 0.240045,
     "end_time": "2022-08-08T09:32:26.086794",
     "exception": false,
     "start_time": "2022-08-08T09:32:25.846749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Columns: \", list(train.columns))\n",
    "\n",
    "#Deletes uneeded rows\n",
    "train.drop(['discourse_id', 'essay_id'] , axis=1, inplace=True)\n",
    "\n",
    "print(\"Null values: \", train.isnull().values.sum())\n",
    "print(\"Duplicates in text row: \", train[\"discourse_text\"].duplicated().values.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks data imbalance in Discourse effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T08:45:57.778383Z",
     "iopub.status.busy": "2022-08-10T08:45:57.777892Z",
     "iopub.status.idle": "2022-08-10T08:45:57.899526Z",
     "shell.execute_reply": "2022-08-10T08:45:57.898000Z",
     "shell.execute_reply.started": "2022-08-10T08:45:57.778336Z"
    }
   },
   "outputs": [],
   "source": [
    "train['discourse_effectiveness'].value_counts().plot.pie(autopct='%.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks data imbalance in discourse type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T08:45:57.904937Z",
     "iopub.status.busy": "2022-08-10T08:45:57.903457Z",
     "iopub.status.idle": "2022-08-10T08:45:58.298091Z",
     "shell.execute_reply": "2022-08-10T08:45:58.297200Z",
     "shell.execute_reply.started": "2022-08-10T08:45:57.904874Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplots(1,1,figsize=(15,8))\n",
    "\n",
    "sns.countplot(data=train,\n",
    "              x=\"discourse_effectiveness\",\n",
    "              hue='discourse_type',\n",
    "              order = ['Ineffective', 'Adequate', 'Effective']\n",
    "             )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Cloud for each Discourse effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T08:45:58.300047Z",
     "iopub.status.busy": "2022-08-10T08:45:58.299229Z",
     "iopub.status.idle": "2022-08-10T08:46:04.818324Z",
     "shell.execute_reply": "2022-08-10T08:46:04.817040Z",
     "shell.execute_reply.started": "2022-08-10T08:45:58.300014Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.subplots(nrows=1, ncols=3, figsize=(18,8))\n",
    "\n",
    "\n",
    "textArr = {\n",
    "    \"Ineffective\": train.loc[train['discourse_effectiveness']=='Ineffective', 'discourse_text'],\n",
    "    \"Adequate\": train.loc[train['discourse_effectiveness']=='Adequate', 'discourse_text'],\n",
    "    \"Effective\": train.loc[train['discourse_effectiveness']=='Effective', 'discourse_text']\n",
    "}\n",
    "\n",
    "figIndex= 1\n",
    "\n",
    "for effectiveness, texts in textArr.items():\n",
    "    for i, x in texts.iteritems():\n",
    "        texts[i] = x.lower() \n",
    "    \n",
    "    allText = \" \".join(texts) + \" \"\n",
    "    \n",
    "    plt.subplot(1,3,figIndex).set_title(effectiveness)\n",
    "    plt.plot()\n",
    "    wordCloud = WordCloud(width = 400, height = 400,\n",
    "            background_color ='white',\n",
    "            stopwords = set(stopwords.words('english')),\n",
    "            min_font_size = 10).generate(allText)\n",
    "    plt.imshow(wordCloud)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    figIndex +=1\n",
    "        \n",
    "\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orinially encodes effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T08:46:04.821258Z",
     "iopub.status.busy": "2022-08-10T08:46:04.820369Z",
     "iopub.status.idle": "2022-08-10T08:46:04.843521Z",
     "shell.execute_reply": "2022-08-10T08:46:04.842511Z",
     "shell.execute_reply.started": "2022-08-10T08:46:04.821219Z"
    }
   },
   "outputs": [],
   "source": [
    "# ordinally encodes effectivness\n",
    "train['discourse_effectiveness'] = train[\"discourse_effectiveness\"].replace(\n",
    "            {\"Ineffective\": 0, \"Adequate\": 1, \"Effective\": 2}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008294,
     "end_time": "2022-08-08T09:32:26.219585",
     "exception": false,
     "start_time": "2022-08-08T09:32:26.211291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Cleans the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T08:46:04.845578Z",
     "iopub.status.busy": "2022-08-10T08:46:04.845000Z",
     "iopub.status.idle": "2022-08-10T08:46:13.104560Z",
     "shell.execute_reply": "2022-08-10T08:46:13.103173Z",
     "shell.execute_reply.started": "2022-08-10T08:46:04.845545Z"
    },
    "papermill": {
     "duration": 8.161659,
     "end_time": "2022-08-08T09:32:34.389816",
     "exception": false,
     "start_time": "2022-08-08T09:32:26.228157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ########## Clean data\n",
    "def cleanText(df):\n",
    "\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        curText = row.discourse_text\n",
    "\n",
    "        # lower case conversion\n",
    "        curText = curText.lower()\n",
    "        # removes all the trailing and leading spaces\n",
    "        curText = curText.strip()\n",
    "        \n",
    "        # Keeping stopwords increased accuracy\n",
    "        \n",
    "        #Removes stop words\n",
    "        #def remove_stop(x):\n",
    "        #    return \" \".join([word for word in str(x).split() if word not in stopWords])\n",
    "        #curText = remove_stop(curText)\n",
    "        \n",
    "        # removing all non alphabetic char\n",
    "        curText = re.sub(r'[^a-z ]+', '', curText)\n",
    "        # stems the text\n",
    "        curText = stemmer.stem(curText)\n",
    "        # removing multiple spaces in a row\n",
    "        curText = re.sub(r'(\\s)+', ' ', curText)\n",
    "        # replaces the text\n",
    "        df.at[index, 'discourse_text'] = curText\n",
    "\n",
    "\n",
    "cleanText(train)\n",
    "\n",
    "print(train['discourse_text'])\n",
    "\n",
    "print(\"\\nCleaned Train Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007765,
     "end_time": "2022-08-08T09:32:34.405817",
     "exception": false,
     "start_time": "2022-08-08T09:32:34.398052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Vectorizes the cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T08:46:13.106572Z",
     "iopub.status.busy": "2022-08-10T08:46:13.106230Z",
     "iopub.status.idle": "2022-08-10T08:46:26.965522Z",
     "shell.execute_reply": "2022-08-10T08:46:26.964567Z",
     "shell.execute_reply.started": "2022-08-10T08:46:13.106542Z"
    },
    "papermill": {
     "duration": 14.42432,
     "end_time": "2022-08-08T09:32:48.838121",
     "exception": false,
     "start_time": "2022-08-08T09:32:34.413801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vectorized strings\n",
    "countVec = TfidfVectorizer(\n",
    "    min_df=3\n",
    ")\n",
    "\n",
    "# Fits the vectorized with train data\n",
    "train_vectors = countVec.fit_transform(train['discourse_text'])\n",
    "\n",
    "# Gets a list of all the words in the vector\n",
    "vector_features = countVec.get_feature_names_out()\n",
    "#print(\"Vector features: \", vector_features)  # Prints all the words fit intoz the in the vectorizer\n",
    "print(\"Feature Counts: \", len(vector_features), \"\\n\\n\")  # Prints the amount of words in the vectorizer\n",
    "# Converts the vectorized data matrix to array\n",
    "train_vec_arr = train_vectors.toarray()\n",
    "# Puts the vectorized data into the dataframe\n",
    "    #train_vec_dataframe = pd.DataFrame(data=train_vec_arr, columns=vector_features)\n",
    "train = pd.concat([train, pd.DataFrame(data=train_vec_arr, columns=vector_features).reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "del train_vectors\n",
    "del train_vec_arr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008068,
     "end_time": "2022-08-08T09:32:48.854376",
     "exception": false,
     "start_time": "2022-08-08T09:32:48.846308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "One Hot Encondes the discourse type row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T08:46:26.968202Z",
     "iopub.status.busy": "2022-08-10T08:46:26.967012Z",
     "iopub.status.idle": "2022-08-10T08:46:26.993378Z",
     "shell.execute_reply": "2022-08-10T08:46:26.992055Z",
     "shell.execute_reply.started": "2022-08-10T08:46:26.968155Z"
    },
    "papermill": {
     "duration": 0.0465,
     "end_time": "2022-08-08T09:32:48.909029",
     "exception": false,
     "start_time": "2022-08-08T09:32:48.862529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One hot encodes discourse type\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "X_categorical_OneHot_train = pd.DataFrame(OH_encoder.fit_transform(train[['discourse_type']]))\n",
    "print(\"One hot enconded train dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009819,
     "end_time": "2022-08-08T09:32:48.930757",
     "exception": false,
     "start_time": "2022-08-08T09:32:48.920938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Combines the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T08:46:26.997130Z",
     "iopub.status.busy": "2022-08-10T08:46:26.996756Z",
     "iopub.status.idle": "2022-08-10T08:46:29.010299Z",
     "shell.execute_reply": "2022-08-10T08:46:29.008955Z",
     "shell.execute_reply.started": "2022-08-10T08:46:26.997095Z"
    },
    "papermill": {
     "duration": 2.04986,
     "end_time": "2022-08-08T09:32:50.989085",
     "exception": false,
     "start_time": "2022-08-08T09:32:48.939225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combineDataFrame(df, restDfs):\n",
    "    # drops the text column as it has been vectorized and type since it's been one hot encoded\n",
    "    df.drop(['discourse_text', 'discourse_type'], inplace=True, axis=1)\n",
    "    #resets index to make concat work\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    for curDf in restDfs:\n",
    "        #resets index to make concat work\n",
    "        curDf.reset_index(drop=True, inplace=True)\n",
    "        df = pd.concat([df, curDf], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Gets the Qcombined and fully cleaned model\n",
    "train = combineDataFrame(train, [X_categorical_OneHot_train])\n",
    "print(\"Fully Combined the Train dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008051,
     "end_time": "2022-08-08T09:32:51.005616",
     "exception": false,
     "start_time": "2022-08-08T09:32:50.997565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Performs Oversampling on Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T08:46:29.012156Z",
     "iopub.status.busy": "2022-08-10T08:46:29.011812Z",
     "iopub.status.idle": "2022-08-10T08:46:48.652904Z",
     "shell.execute_reply": "2022-08-10T08:46:48.651788Z",
     "shell.execute_reply.started": "2022-08-10T08:46:29.012124Z"
    },
    "papermill": {
     "duration": 26.168655,
     "end_time": "2022-08-08T09:33:17.183028",
     "exception": false,
     "start_time": "2022-08-08T09:32:51.014373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Gets the y value\n",
    "yFinished = train['discourse_effectiveness']\n",
    "#drops the y value\n",
    "train.drop('discourse_effectiveness', axis=1, inplace=True)\n",
    "\n",
    "# Performs oversampling with a 1-1 ratio\n",
    "\n",
    "#smote = SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))\n",
    "ros = RandomOverSampler(sampling_strategy='auto',random_state=42)\n",
    "train, yFinished = ros.fit_resample(train, yFinished)\n",
    "print(\"Over Sampling on data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008277,
     "end_time": "2022-08-08T09:33:17.201819",
     "exception": false,
     "start_time": "2022-08-08T09:33:17.193542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Train Test split to make Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T08:46:48.654923Z",
     "iopub.status.busy": "2022-08-10T08:46:48.654585Z",
     "iopub.status.idle": "2022-08-10T08:46:57.106716Z",
     "shell.execute_reply": "2022-08-10T08:46:57.105609Z",
     "shell.execute_reply.started": "2022-08-10T08:46:48.654892Z"
    },
    "papermill": {
     "duration": 7.788858,
     "end_time": "2022-08-08T09:33:24.999044",
     "exception": false,
     "start_time": "2022-08-08T09:33:17.210186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "XTrain, XValid, yTrain, yValid = train_test_split(train, yFinished, test_size=0.2, random_state=42) \n",
    "\n",
    "del train\n",
    "gc.collect()\n",
    "\n",
    "print(\"Split into train and validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008581,
     "end_time": "2022-08-08T09:33:25.016469",
     "exception": false,
     "start_time": "2022-08-08T09:33:25.007888",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ***Models Section***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008777,
     "end_time": "2022-08-08T09:33:25.034282",
     "exception": false,
     "start_time": "2022-08-08T09:33:25.025505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Model Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T08:46:57.108555Z",
     "iopub.status.busy": "2022-08-10T08:46:57.108230Z",
     "iopub.status.idle": "2022-08-10T08:46:57.114411Z",
     "shell.execute_reply": "2022-08-10T08:46:57.112742Z",
     "shell.execute_reply.started": "2022-08-10T08:46:57.108525Z"
    },
    "papermill": {
     "duration": 0.172849,
     "end_time": "2022-08-08T09:33:25.232933",
     "exception": false,
     "start_time": "2022-08-08T09:33:25.060084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008349,
     "end_time": "2022-08-08T09:33:25.249983",
     "exception": false,
     "start_time": "2022-08-08T09:33:25.241634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T08:46:57.116749Z",
     "iopub.status.busy": "2022-08-10T08:46:57.116362Z",
     "iopub.status.idle": "2022-08-10T08:56:49.652385Z",
     "shell.execute_reply": "2022-08-10T08:56:49.651497Z",
     "shell.execute_reply.started": "2022-08-10T08:46:57.116717Z"
    },
    "papermill": {
     "duration": 567.273473,
     "end_time": "2022-08-08T09:42:52.532091",
     "exception": false,
     "start_time": "2022-08-08T09:33:25.258618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Models = {\n",
    "    \"LogisticReg\": LogisticRegression(C=1, max_iter=500, multi_class=\"multinomial\")\n",
    "    #\"SDGCLassifer\": SGDClassifier(loss='log_loss', max_iter=10000, alpha=0.00001)\n",
    "    }\n",
    "\n",
    "modelsTrained = {}\n",
    "\n",
    "for modelName, model in Models.items():\n",
    "\n",
    "    fitModel = model.fit(XTrain, yTrain)\n",
    "    \n",
    "    trainPred = fitModel.predict(XTrain)\n",
    "    trainMeanError = accuracy_score(trainPred, yTrain)\n",
    "    print(modelName, \" Train Accuracy: \", trainMeanError)\n",
    "    trainConfusionMatrix = confusion_matrix(trainPred, yTrain)\n",
    "    print(trainConfusionMatrix)\n",
    "\n",
    "    validPred = fitModel.predict(XValid)\n",
    "    validMeanError = accuracy_score(validPred, yValid)\n",
    "    print(modelName, \" Valid Accuracy: \", validMeanError)\n",
    "    validConfusionMatrix = confusion_matrix(validPred, yValid)\n",
    "    \n",
    "    labels = [ 'Ineffective', \"Adequate\", \"Effective\"]\n",
    "    \n",
    "    heatMapData = pd.DataFrame(validConfusionMatrix, index=labels, columns=labels)\n",
    "    \n",
    "    dataSum = heatMapData.sum(axis = 1)\n",
    "    \n",
    "    ineffectivePerc = heatMapData.at['Ineffective','Ineffective'] / dataSum['Ineffective']\n",
    "    adequatePerc = heatMapData.at['Adequate','Adequate'] / dataSum['Adequate'] \n",
    "    effectivePerc = heatMapData.at['Effective','Effective'] / dataSum['Effective']  \n",
    "    \n",
    "    print(\"Ineffective Accuracy: \", ineffectivePerc)\n",
    "    print(\"Adequate Accuracy: \", adequatePerc)\n",
    "    print(\"Effective Accuracy: \", effectivePerc)\n",
    "    \n",
    "    sns.heatmap(heatMapData, annot = True, fmt = 'd')\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.xlabel('PRED')\n",
    "    plt.ylabel('REAL')\n",
    "    plt.show()\n",
    "    #Saves the fit model\n",
    "    modelsTrained[modelName] = fitModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014201,
     "end_time": "2022-08-08T09:42:52.560921",
     "exception": false,
     "start_time": "2022-08-08T09:42:52.546720",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Clears Train data memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T08:56:49.654269Z",
     "iopub.status.busy": "2022-08-10T08:56:49.653584Z",
     "iopub.status.idle": "2022-08-10T08:56:49.897610Z",
     "shell.execute_reply": "2022-08-10T08:56:49.896242Z",
     "shell.execute_reply.started": "2022-08-10T08:56:49.654227Z"
    },
    "papermill": {
     "duration": 0.408298,
     "end_time": "2022-08-08T09:42:52.983709",
     "exception": false,
     "start_time": "2022-08-08T09:42:52.575411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del XTrain\n",
    "del XValid\n",
    "del yTrain\n",
    "del yValid\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008635,
     "end_time": "2022-08-08T09:42:53.019193",
     "exception": false,
     "start_time": "2022-08-08T09:42:53.010558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Setting up test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T08:56:49.899430Z",
     "iopub.status.busy": "2022-08-10T08:56:49.899082Z",
     "iopub.status.idle": "2022-08-10T08:56:50.090506Z",
     "shell.execute_reply": "2022-08-10T08:56:50.089203Z",
     "shell.execute_reply.started": "2022-08-10T08:56:49.899399Z"
    },
    "papermill": {
     "duration": 0.195513,
     "end_time": "2022-08-08T09:42:53.223572",
     "exception": false,
     "start_time": "2022-08-08T09:42:53.028059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./Dataset/test.csv\")\n",
    "\n",
    "testID = test['discourse_id']\n",
    "\n",
    "test.drop(['discourse_id', 'essay_id'] , axis=1, inplace=True)\n",
    "cleanText(test)\n",
    "\n",
    "test_vectors = countVec.transform(test['discourse_text'])\n",
    "test_vec_arr = test_vectors.toarray()\n",
    "    #test_vec_dataframe = pd.DataFrame(data=test_vec_arr, columns=vector_features)\n",
    "test = pd.concat([test, pd.DataFrame(data=test_vec_arr, columns=vector_features).reset_index(drop=True)], axis=1)\n",
    "\n",
    "del test_vectors\n",
    "del test_vec_arr\n",
    "gc.collect()\n",
    "\n",
    "X_categorical_OneHot_test = pd.DataFrame(OH_encoder.transform(test[['discourse_type']]))\n",
    "test = combineDataFrame(test, [X_categorical_OneHot_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008752,
     "end_time": "2022-08-08T09:42:53.241257",
     "exception": false,
     "start_time": "2022-08-08T09:42:53.232505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Exporing Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T08:56:50.092368Z",
     "iopub.status.busy": "2022-08-10T08:56:50.091936Z",
     "iopub.status.idle": "2022-08-10T08:56:50.197281Z",
     "shell.execute_reply": "2022-08-10T08:56:50.195734Z",
     "shell.execute_reply.started": "2022-08-10T08:56:50.092338Z"
    },
    "papermill": {
     "duration": 0.128043,
     "end_time": "2022-08-08T09:42:53.378244",
     "exception": false,
     "start_time": "2022-08-08T09:42:53.250201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "testPred = modelsTrained['LogisticReg'].predict_proba(test)\n",
    "\n",
    "submission.loc[:, \"discourse_id\"] =testID\n",
    "submission.loc[:,\"Ineffective\"] = testPred[:,0]\n",
    "submission.loc[:,\"Adequate\"] = testPred[:,1]\n",
    "submission.loc[:,\"Effective\"] = testPred[:,2]\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T08:56:50.200310Z",
     "iopub.status.busy": "2022-08-10T08:56:50.199365Z",
     "iopub.status.idle": "2022-08-10T08:56:50.214029Z",
     "shell.execute_reply": "2022-08-10T08:56:50.212209Z",
     "shell.execute_reply.started": "2022-08-10T08:56:50.200245Z"
    },
    "papermill": {
     "duration": 0.036421,
     "end_time": "2022-08-08T09:42:53.430464",
     "exception": false,
     "start_time": "2022-08-08T09:42:53.394043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
